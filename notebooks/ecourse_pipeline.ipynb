{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9db2594-395c-44c5-8edb-a094d4f654ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load CSV into dataframe\n",
    "df_raw = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/Volumes/trial/default/course_engagement/online_course_engagement_data_cleaned.csv\")\n",
    "\n",
    "# Save as managed delta table (bronze)\n",
    "df_raw.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze_ecourse_engagement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1bcb251-ce5d-4093-8516-a0217410f8ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, sum as spark_sum\n",
    "\n",
    "df_raw.printSchema()\n",
    "\n",
    "display(df_raw)\n",
    "\n",
    "# Checking for nulls\n",
    "df_raw.select([spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_raw.columns]).show()\n",
    "\n",
    "# Unique values\n",
    "for column in df_raw.columns:\n",
    "    print(f\"{column}: {df_raw.select(column).distinct().count()} unique values\")\n",
    "\n",
    "# Rename columns to snake case\n",
    "df_renamed = df_raw.selectExpr(\n",
    "    \"UserID as user_id\",\n",
    "    \"CourseCategory as course_category\",\n",
    "    \"TimeSpentOnCourse as time_spent_on_course\",\n",
    "    \"NumberOfVideosWatched as number_of_videos_watched\",\n",
    "    \"NumberOfQuizzesTaken as number_of_quizzes_taken\",\n",
    "    \"QuizScores as quiz_scores\",\n",
    "    \"CompletionRate as completion_rate\",\n",
    "    \"DeviceType as device_type\",\n",
    "    \"CourseCompletion as course_completion\"\n",
    ")\n",
    "\n",
    "# Add label columns for readability\n",
    "df_labeled = df_renamed \\\n",
    "    .withColumn(\"device_type_label\", when(col(\"device_type\") == 0, \"Desktop\").otherwise(\"Mobile\")) \\\n",
    "    .withColumn(\"course_completion_label\", when(col(\"course_completion\") == 1, \"Completed\").otherwise(\"Not Completed\"))\n",
    "\n",
    "# Show sample of transformed data\n",
    "display(df_labeled.select(\"device_type\", \"device_type_label\", \"course_completion\", \"course_completion_label\"))\n",
    "\n",
    "# Save as managed delta table (silver)\n",
    "df_labeled.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_ecourse_engagement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc3d28c1-8649-4276-b3e8-0ccf233f40ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Basic data quality checks\n",
    "# Count records with negative quiz scores\n",
    "invalid_quiz_scores = df_renamed.filter((col(\"quiz_scores\") < 0) | (col(\"quiz_scores\") > 100))\n",
    "print(f\"Invalid quiz score rows: {invalid_quiz_scores.count()}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ecourse_pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}